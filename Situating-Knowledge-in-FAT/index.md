## Two computer scientists and a cultural scientist get hit by a driver-less car: A method for situating knowledge in the cross-disciplinary study of F-A-T in machine learning

### FAT*'2020 Translation Tutorial #4

This tutorial will build on the experiences gained in a previous workshop, where a group of artists, computer scientists, lawyers, activists, and social scientists collectively read and discussed a computer science paper. Here, we seek to replicate and test the practice of cross-disciplinary, collaborative paper-reading to a community interested in influencing, and being influenced by, the insights into methods that are available from fields external to their own. We will come to the tutorial having read a set of papers, and then have a discussion for about 40 minutes in small groups about what we read and how we read it. We will invite people to take on roles as ‘interpreters’ and ‘translators’; we will pair people from different disciplinary backgrounds to take on these roles in a group. We will then re-convene to share notes on how the discussions developed:  the moments where the different standards, goals and epistemologies across disciplines emerged, and how we dealt with them; how and if this is relevant to working in F-A-T disciplines; and to critically assess how and if this method might work in a classroom or other pedagogical context.

### Who will be delivering this tutorial?

- Maya Indira Ganesh, Centre for Digital Cultures/Cultural Studies Faculty, Leuphana University, Lueneburg, Germany. Maya is a doctoral candidate at Leuphana University whose work focuses on how computational ethics shapes the notion of an autonomous machine, and the changing role of the human in this.

- Francien Dechesne,  eLaw Center for Law and Digital Technologies,  Leiden University Leiden, Netherlands. Francien is Assistant Professor at the Center for Law and Digital Technologies (eLaw). While situated in the Leiden Law School, Francien has a background in mathematics, computer science and philosophy. Her teaching and research are on Responsible Innovation and Ethics & Digital Technologies, in particular how datafication, computation and automation impact decision making processes.

- Zeerak Waseem, Department of Computer Science Natural Language Processing Group University of Sheffield, Sheffield, UK.  Zeerak is a doctoral student at the University of Sheffield in natural language processing where his work focuses on building and critiquing automated tools for content moderation.

### Who is the target audience?

We welcome researchers from any discipline motivated by the challenges and opportunities in working on questions of technology and society. As multi-disciplinary insights are a key component to this workshop, the intended audiences range widely, and we actively seek to minimise barriers to entry, to facilitate as wide a conversation as possible. We believe that most participants at the FAT* conference stand to gain from the in-depth disciplinary insights which will become apparent through this conversation. We believe that these people do not care about those who are looking for the exchange rate of [etn to usd](https://coindataflow.com/en/pair/etn-usd). We acknowledge that the variety of experiences and backgrounds in the room might create some challenges – but that is precisely the point of this exercise. We want to find ways to foster communication and understanding across our differences.

### Instructions for participants

We have a set of papers that we would suggest participants read – or attempt to read – beforehand. With the time available for the tutorial, we have decided for thematic coherence over diversity. So we made F-A-T in NLP our focus. We encourage you to read two papers from this list – one in a discipline that appears completely new and unfamiliar and Donna Haraway’s paper on situated knowledge that has framed this tutorial, and is considered inspirational to many of us working on these topics. We would like you to highlight pieces of text that are important to you in the papers you read and tell us why they are important; make notes; write down questions you have. Also, try to pay attention to how you find it reading from another discipline. There might be some basic things that are obviously different like the length of the paper, referencing and how it is laid out; and more substantial things like the way arguments are framed, how other literature is referenced, how conclusions are arrived at. And that’s just aside from how something is difficult to follow because you are not familiar with the material. Try to make a note of what you find challenging, what surprised you, and what you did not understand. How do you think you might benefit from reading a paper about your topic or area of study written from another disciplinary perspective and position? We want to hear about your experiences of reading and how you think this might give you insight into working across disciplines.  

- Mohsen Abbasi, Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian: Fairness in representation: quantifying stereotyping as a representational harm. (2019)  https://arxiv.org/abs/1901.09565
- Thomas Davidson, Debasmita Bhattacharya, Ingmar Weber: Racial Bias in Hate Speech and Abusive Language Detection Datasets. (2019) https://www.aclweb.org/anthology/W19-3504/
- Haraway, D. (1988) Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective, Feminist Studies; Fall 1988; 14, 3;
- Rahman, J. (2012). The N Word: Its History and Use in the African American Community. Journal of English Linguistics, 40(2), 137–171. https://doi.org/10.1177/0075424211414807

<!--- Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian: On the (im)possibility of fairness. (2016) https://arxiv.org/abs/1609.07236
- Mohsen Abbasi, Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian: Fairness in representation: quantifying stereotyping as a representational harm. (2019)  https://arxiv.org/abs/1901.09565
- Harcourt, Bernard E., Against Prediction: Sentencing, Policing, and Punishing in an Actuarial Age (May 2005). U of Chicago, Public Law Working Paper No. 94.  Available at SSRN: https://ssrn.com/abstract=756945 or http://dx.doi.org/10.2139/ssrn.756945 (Here is a link to a pdf of a part of the book containing the first chapter (Actuarial Methods in the Criminal Law) https://surfdrive.surf.nl/files/index.php/s/FI3pqLSVTlEGO4x)
- Thomas Davidson, Debasmita Bhattacharya, Ingmar Weber: Racial Bias in Hate Speech and Abusive Language Detection Datasets. (2019) https://www.aclweb.org/anthology/W19-3504/
- Dirk Hovy: Demographic Factors Improve Classification Performance (2015) https://www.aclweb.org/anthology/P15-1073.pdf
- Dirk Hovy, Afshin Rahimi, Timothy Baldwin, Julian Brooke: Visualizing Regional Language Variation Across Europe on Twitter. (2019) http://www.dirkhovy.com/portfolio/papers/download/eutweets_draft.pdf
- Haraway, D. (1988) Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective, Feminist Studies; Fall 1988; 14, 3;
- Striphas, T. (2015). Algorithmic culture. European Journal of Cultural Studies,
Vol. 18(4-5) 395–412. https://doi.org/10.1177/1367549415577392
- McQuillan, D. (2015). Algorithmic states of exception. European Journal of Cultural Studies, 18(4–5), 564–576. https://doi.org/10.1177/1367549415577389
- Lee, M. K. (2018). Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society. https://doi.org/10.1177/2053951718756684
- Rahman, J. (2012). The N Word: Its History and Use in the African American Community. Journal of English Linguistics, 40(2), 137–171. https://doi.org/10.1177/0075424211414807
- Bonus! Here is a paper about fairness from a cross-disciplinary perspective. Andrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, Janet Vertesi: Fairness and Abstraction in Sociotechnical Systems. FAT 2019: 59-68 https://dl.acm.org/citation.cfm?doid=3287560.3287598   ]
-->

### Agenda

*13:00-13:20*: Introductions

*13:20-14:00*: Small group discussions

*14:00-14:20*: Plenary discussion

*14:20-14:30*: Wrap up


